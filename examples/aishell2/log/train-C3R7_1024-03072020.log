
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
-----------  Configuration Arguments -----------
augment_conf_path: conf/augmentation.config
batch_size: 16
dev_manifest: data/aishell2/manifest.dev
init_from_pretrained_model: None
is_local: 1
learning_rate: 0.0005
max_duration: 27.0
mean_std_path: data/aishell2/mean_std.npz
min_duration: 0.0
num_conv_layers: 2
num_epoch: 10
num_iter_print: 100
num_rnn_layers: 7
num_samples: 999078
output_model_dir: ./checkpoints/aishell2-C2R71024
rnn_layer_size: 1024
save_epoch: 1
share_rnn_weights: 0
shuffle_method: batch_shuffle_clipped
specgram_type: linear
test_off: 0
train_manifest: data/aishell2/manifest.train
use_gpu: 1
use_gru: 1
use_sortagrad: 1
vocab_path: data/aishell2/vocab.txt
------------------------------------------------
W0308 02:38:00.680461  5551 device_context.cc:236] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 10.2, Runtime API Version: 10.0
W0308 02:38:00.683604  5551 device_context.cc:244] device: 0, cuDNN Version: 7.5.
W0308 02:38:00.683619  5551 device_context.cc:270] WARNING: device: 0. The installed Paddle is compiled with CUDNN 7.6, but CUDNN version in your machine is 7.5, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.
I0308 02:38:01.652289  5551 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 8. And the Program will be copied 8 copies
W0308 02:38:22.258895  5551 fuse_all_reduce_op_pass.cc:72] Find all_reduce operators: 78. To make the speed faster, some all_reduce ops are fused during training, after fusion, the number of all_reduce ops is 78.
I0308 02:38:22.276695  5551 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1
I0308 02:38:22.653481  5551 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True
I0308 02:38:22.766775  5551 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0
epoch: 0, batch: 0, train loss: 266.389709

epoch: 0, batch: 100, train loss: 14.643205

epoch: 0, batch: 200, train loss: 18.783039

epoch: 0, batch: 300, train loss: 16.319601

epoch: 0, batch: 400, train loss: 15.550798

epoch: 0, batch: 500, train loss: 36.231358

epoch: 0, batch: 600, train loss: 7.526259

epoch: 0, batch: 700, train loss: 9.693541

epoch: 0, batch: 800, train loss: 11.050488

epoch: 0, batch: 900, train loss: 16.851410

epoch: 0, batch: 1000, train loss: 11.223852

epoch: 0, batch: 1100, train loss: 27.162655

epoch: 0, batch: 1200, train loss: 3.561747

epoch: 0, batch: 1300, train loss: 7.677537

epoch: 0, batch: 1400, train loss: 15.435759

epoch: 0, batch: 1500, train loss: 4.905540

epoch: 0, batch: 1600, train loss: 1.488882

epoch: 0, batch: 1700, train loss: 15.711305

epoch: 0, batch: 1800, train loss: 1.932037

epoch: 0, batch: 1900, train loss: 8.818229

epoch: 0, batch: 2000, train loss: 11.814840

epoch: 0, batch: 2100, train loss: 12.764179

epoch: 0, batch: 2200, train loss: 4.955816

epoch: 0, batch: 2300, train loss: 7.180516

epoch: 0, batch: 2400, train loss: 6.978434

epoch: 0, batch: 2500, train loss: 11.567290

epoch: 0, batch: 2600, train loss: 9.700611

epoch: 0, batch: 2700, train loss: 13.249578

epoch: 0, batch: 2800, train loss: 10.341576

epoch: 0, batch: 2900, train loss: 9.572085

epoch: 0, batch: 3000, train loss: 10.079433

epoch: 0, batch: 3100, train loss: 5.266055

epoch: 0, batch: 3200, train loss: 3.410822

epoch: 0, batch: 3300, train loss: 6.417411

epoch: 0, batch: 3400, train loss: 6.417211

epoch: 0, batch: 3500, train loss: 10.835171

epoch: 0, batch: 3600, train loss: 7.900051

epoch: 0, batch: 3700, train loss: 10.793722

epoch: 0, batch: 3800, train loss: 8.832756

epoch: 0, batch: 3900, train loss: 3.843055

epoch: 0, batch: 4000, train loss: 16.874084

epoch: 0, batch: 4100, train loss: 5.880843

epoch: 0, batch: 4200, train loss: 7.375375

epoch: 0, batch: 4300, train loss: 7.142552

epoch: 0, batch: 4400, train loss: 9.073290

epoch: 0, batch: 4500, train loss: 11.128116

epoch: 0, batch: 4600, train loss: 18.681671

epoch: 0, batch: 4700, train loss: 10.221188

epoch: 0, batch: 4800, train loss: 3.143439

epoch: 0, batch: 4900, train loss: 1.567853

epoch: 0, batch: 5000, train loss: 8.583914

epoch: 0, batch: 5100, train loss: 10.990664

epoch: 0, batch: 5200, train loss: 6.722493

epoch: 0, batch: 5300, train loss: 6.674237

epoch: 0, batch: 5400, train loss: 5.173289

epoch: 0, batch: 5500, train loss: 6.158029

epoch: 0, batch: 5600, train loss: 13.737138

epoch: 0, batch: 5700, train loss: 10.641521

epoch: 0, batch: 5800, train loss: 8.457963

epoch: 0, batch: 5900, train loss: 14.134121

epoch: 0, batch: 6000, train loss: 13.162509

epoch: 0, batch: 6100, train loss: 13.246330

epoch: 0, batch: 6200, train loss: 12.226273

epoch: 0, batch: 6300, train loss: 6.373840

epoch: 0, batch: 6400, train loss: 14.716702

epoch: 0, batch: 6500, train loss: 14.853157

epoch: 0, batch: 6600, train loss: 12.715958

epoch: 0, batch: 6700, train loss: 7.679397

epoch: 0, batch: 6800, train loss: 9.062168

epoch: 0, batch: 6900, train loss: 5.198163

epoch: 0, batch: 7000, train loss: 7.605088

epoch: 0, batch: 7100, train loss: 12.992068

epoch: 0, batch: 7200, train loss: 14.660244

epoch: 0, batch: 7300, train loss: 8.462021

epoch: 0, batch: 7400, train loss: 13.982449

epoch: 0, batch: 7500, train loss: 12.052756

epoch: 0, batch: 7600, train loss: 58.099697

epoch: 0, batch: 7700, train loss: 15.463350

epoch: 0, batch: 7800, train loss: 23.520393


----------Begin test...
--------Time: 7391.799665 sec, epoch: 0, train loss: 14.446986, test loss: 8.508069
save parameters at ./checkpoints/aishell2-C2R71024/epoch_0
epoch: 1, batch: 0, train loss: 7.027521

epoch: 1, batch: 100, train loss: 4.291234

epoch: 1, batch: 200, train loss: 13.981075

epoch: 1, batch: 300, train loss: 4.301248

epoch: 1, batch: 400, train loss: 8.971613

epoch: 1, batch: 500, train loss: 2.126403

epoch: 1, batch: 600, train loss: 6.009768

epoch: 1, batch: 700, train loss: 5.363988

epoch: 1, batch: 800, train loss: 6.723818

epoch: 1, batch: 900, train loss: 2.797677

epoch: 1, batch: 1000, train loss: 1.695730

epoch: 1, batch: 1100, train loss: 20.117414

epoch: 1, batch: 1200, train loss: 8.045519

epoch: 1, batch: 1300, train loss: 4.216828

epoch: 1, batch: 1400, train loss: 10.136326

epoch: 1, batch: 1500, train loss: 5.337255

epoch: 1, batch: 1600, train loss: 10.425842

epoch: 1, batch: 1700, train loss: 4.336848

epoch: 1, batch: 1800, train loss: 4.883671

epoch: 1, batch: 1900, train loss: 1.750469

epoch: 1, batch: 2000, train loss: 7.007639

epoch: 1, batch: 2100, train loss: 2.174285

epoch: 1, batch: 2200, train loss: 4.761104

epoch: 1, batch: 2300, train loss: 6.509105

epoch: 1, batch: 2400, train loss: 9.340726

epoch: 1, batch: 2500, train loss: 6.346707

epoch: 1, batch: 2600, train loss: 11.167775

epoch: 1, batch: 2700, train loss: 4.550416

epoch: 1, batch: 2800, train loss: 3.714384

epoch: 1, batch: 2900, train loss: 1.724797

epoch: 1, batch: 3000, train loss: 7.049395

epoch: 1, batch: 3100, train loss: 11.864667

epoch: 1, batch: 3200, train loss: 8.574993

epoch: 1, batch: 3300, train loss: 3.090526

epoch: 1, batch: 3400, train loss: 7.206815

epoch: 1, batch: 3500, train loss: 1.443876

epoch: 1, batch: 3600, train loss: 11.714952

epoch: 1, batch: 3700, train loss: 6.283939

epoch: 1, batch: 3800, train loss: 5.073881

epoch: 1, batch: 3900, train loss: 6.608174

epoch: 1, batch: 4000, train loss: 2.123190

epoch: 1, batch: 4100, train loss: 2.219366

epoch: 1, batch: 4200, train loss: 7.678821

epoch: 1, batch: 4300, train loss: 7.337203

epoch: 1, batch: 4400, train loss: 7.525799

epoch: 1, batch: 4500, train loss: 11.204440

epoch: 1, batch: 4600, train loss: 10.182502

epoch: 1, batch: 4700, train loss: 7.752563

epoch: 1, batch: 4800, train loss: 6.675176

epoch: 1, batch: 4900, train loss: 9.811477

epoch: 1, batch: 5000, train loss: 3.431223

epoch: 1, batch: 5100, train loss: 1.097057

epoch: 1, batch: 5200, train loss: 9.083086

epoch: 1, batch: 5300, train loss: 3.447020

epoch: 1, batch: 5400, train loss: 6.929487

epoch: 1, batch: 5500, train loss: 1.094297

epoch: 1, batch: 5600, train loss: 9.410931

epoch: 1, batch: 5700, train loss: 6.646910

epoch: 1, batch: 5800, train loss: 0.511504

epoch: 1, batch: 5900, train loss: 3.082865

epoch: 1, batch: 6000, train loss: 6.360728

epoch: 1, batch: 6100, train loss: 4.810247

epoch: 1, batch: 6200, train loss: 8.038905

epoch: 1, batch: 6300, train loss: 5.663600

epoch: 1, batch: 6400, train loss: 5.537203

epoch: 1, batch: 6500, train loss: 2.188508

epoch: 1, batch: 6600, train loss: 2.875527

epoch: 1, batch: 6700, train loss: 1.852201

epoch: 1, batch: 6800, train loss: 2.977940

epoch: 1, batch: 6900, train loss: 4.867102

epoch: 1, batch: 7000, train loss: 8.117327

epoch: 1, batch: 7100, train loss: 6.416361

epoch: 1, batch: 7200, train loss: 1.749691

epoch: 1, batch: 7300, train loss: 5.626848

epoch: 1, batch: 7400, train loss: 4.413911

epoch: 1, batch: 7500, train loss: 0.743266

epoch: 1, batch: 7600, train loss: 11.547524

epoch: 1, batch: 7700, train loss: 15.372799

epoch: 1, batch: 7800, train loss: 9.714021


----------Begin test...
--------Time: 7378.483598 sec, epoch: 1, train loss: 6.137558, test loss: 6.156615
save parameters at ./checkpoints/aishell2-C2R71024/epoch_1
epoch: 2, batch: 0, train loss: 9.142426

epoch: 2, batch: 100, train loss: 6.229473

epoch: 2, batch: 200, train loss: 11.349227

epoch: 2, batch: 300, train loss: 6.289061

epoch: 2, batch: 400, train loss: 0.510297

epoch: 2, batch: 500, train loss: 7.922989

epoch: 2, batch: 600, train loss: 6.691353

epoch: 2, batch: 700, train loss: 6.786836

epoch: 2, batch: 800, train loss: 5.711554

epoch: 2, batch: 900, train loss: 5.650592

epoch: 2, batch: 1000, train loss: 1.780029

epoch: 2, batch: 1100, train loss: 8.102322

epoch: 2, batch: 1200, train loss: 2.244669

epoch: 2, batch: 1300, train loss: 2.263517

epoch: 2, batch: 1400, train loss: 0.565767

epoch: 2, batch: 1500, train loss: 3.993807

epoch: 2, batch: 1600, train loss: 2.684513

epoch: 2, batch: 1700, train loss: 5.896423

epoch: 2, batch: 1800, train loss: 4.091477

epoch: 2, batch: 1900, train loss: 4.201163

epoch: 2, batch: 2000, train loss: 4.340626

epoch: 2, batch: 2100, train loss: 3.614252

epoch: 2, batch: 2200, train loss: 6.589667

epoch: 2, batch: 2300, train loss: 4.284598

epoch: 2, batch: 2400, train loss: 7.668701

epoch: 2, batch: 2500, train loss: 8.244022

epoch: 2, batch: 2600, train loss: 1.691509

epoch: 2, batch: 2700, train loss: 1.525583

epoch: 2, batch: 2800, train loss: 2.963855

epoch: 2, batch: 2900, train loss: 4.730901

epoch: 2, batch: 3000, train loss: 0.308305

epoch: 2, batch: 3100, train loss: 3.009833

epoch: 2, batch: 3200, train loss: 4.582311

epoch: 2, batch: 3300, train loss: 4.766612

epoch: 2, batch: 3400, train loss: 12.014595

epoch: 2, batch: 3500, train loss: 4.159424

epoch: 2, batch: 3600, train loss: 3.063204

epoch: 2, batch: 3700, train loss: 3.954909

epoch: 2, batch: 3800, train loss: 4.212498

epoch: 2, batch: 3900, train loss: 5.427485

epoch: 2, batch: 4000, train loss: 3.656851

epoch: 2, batch: 4100, train loss: 3.189970

epoch: 2, batch: 4200, train loss: 4.462179

epoch: 2, batch: 4300, train loss: 1.554050

epoch: 2, batch: 4400, train loss: 5.626528

epoch: 2, batch: 4500, train loss: 2.890326

epoch: 2, batch: 4600, train loss: 8.749556

epoch: 2, batch: 4700, train loss: 2.895369

epoch: 2, batch: 4800, train loss: 0.895612

epoch: 2, batch: 4900, train loss: 7.282081

epoch: 2, batch: 5000, train loss: 3.889217

epoch: 2, batch: 5100, train loss: 1.933610

epoch: 2, batch: 5200, train loss: 1.386799

epoch: 2, batch: 5300, train loss: 2.779632

epoch: 2, batch: 5400, train loss: 2.539514

epoch: 2, batch: 5500, train loss: 2.460059

epoch: 2, batch: 5600, train loss: 3.693636

epoch: 2, batch: 5700, train loss: 1.218853

epoch: 2, batch: 5800, train loss: 5.669483

epoch: 2, batch: 5900, train loss: 1.309383

epoch: 2, batch: 6000, train loss: 4.279263

epoch: 2, batch: 6100, train loss: 7.546326

epoch: 2, batch: 6200, train loss: 1.522829

epoch: 2, batch: 6300, train loss: 4.008988

epoch: 2, batch: 6400, train loss: 0.092480

epoch: 2, batch: 6500, train loss: 0.483195

epoch: 2, batch: 6600, train loss: 0.091513

epoch: 2, batch: 6700, train loss: 1.328697

epoch: 2, batch: 6800, train loss: 8.493009

epoch: 2, batch: 6900, train loss: 8.292596

epoch: 2, batch: 7000, train loss: 0.499626

epoch: 2, batch: 7100, train loss: 26.140293

epoch: 2, batch: 7200, train loss: 0.745959

epoch: 2, batch: 7300, train loss: 6.269446

epoch: 2, batch: 7400, train loss: 8.496672

epoch: 2, batch: 7500, train loss: 3.963574

epoch: 2, batch: 7600, train loss: 0.761128

epoch: 2, batch: 7700, train loss: 5.708947

epoch: 2, batch: 7800, train loss: 0.527496


----------Begin test...
--------Time: 7218.406589 sec, epoch: 2, train loss: 4.437913, test loss: 4.759216
save parameters at ./checkpoints/aishell2-C2R71024/epoch_2
epoch: 3, batch: 0, train loss: 1.738321

epoch: 3, batch: 100, train loss: 4.585856

epoch: 3, batch: 200, train loss: 3.736643

epoch: 3, batch: 300, train loss: 0.424624

epoch: 3, batch: 400, train loss: 3.348456

epoch: 3, batch: 500, train loss: 3.660935

epoch: 3, batch: 600, train loss: 3.823252

epoch: 3, batch: 700, train loss: 5.590799

epoch: 3, batch: 800, train loss: 3.701188

epoch: 3, batch: 900, train loss: 2.738740

epoch: 3, batch: 1000, train loss: 0.643385

epoch: 3, batch: 1100, train loss: 4.083060

epoch: 3, batch: 1200, train loss: 5.151533

epoch: 3, batch: 1300, train loss: 4.124905

epoch: 3, batch: 1400, train loss: 0.754089

epoch: 3, batch: 1500, train loss: 3.310909

epoch: 3, batch: 1600, train loss: 0.107665

epoch: 3, batch: 1700, train loss: 6.556789

epoch: 3, batch: 1800, train loss: 0.178219

epoch: 3, batch: 1900, train loss: 2.113121

epoch: 3, batch: 2000, train loss: 5.207635

epoch: 3, batch: 2100, train loss: 1.574971

epoch: 3, batch: 2200, train loss: 5.171887

epoch: 3, batch: 2300, train loss: 2.967907

epoch: 3, batch: 2400, train loss: 1.721927

epoch: 3, batch: 2500, train loss: 5.019660

epoch: 3, batch: 2600, train loss: 1.607345

epoch: 3, batch: 2700, train loss: 7.049900

epoch: 3, batch: 2800, train loss: 1.908146

epoch: 3, batch: 2900, train loss: 6.261313

epoch: 3, batch: 3000, train loss: 8.977026

epoch: 3, batch: 3100, train loss: 2.486150

epoch: 3, batch: 3200, train loss: 7.287684

epoch: 3, batch: 3300, train loss: 1.586069

epoch: 3, batch: 3400, train loss: 0.507834

epoch: 3, batch: 3500, train loss: 3.896177

epoch: 3, batch: 3600, train loss: 4.893812

epoch: 3, batch: 3700, train loss: 2.043660

epoch: 3, batch: 3800, train loss: 3.264670

epoch: 3, batch: 3900, train loss: 1.413023

epoch: 3, batch: 4000, train loss: 1.588476

epoch: 3, batch: 4100, train loss: 4.953669

epoch: 3, batch: 4200, train loss: 5.292869

epoch: 3, batch: 4300, train loss: 3.836650

epoch: 3, batch: 4400, train loss: 2.893425

epoch: 3, batch: 4500, train loss: 9.092498

epoch: 3, batch: 4600, train loss: 7.719386

epoch: 3, batch: 4700, train loss: 0.694243

epoch: 3, batch: 4800, train loss: 1.466426

epoch: 3, batch: 4900, train loss: 2.678898

epoch: 3, batch: 5000, train loss: 5.662718

epoch: 3, batch: 5100, train loss: 0.691041

epoch: 3, batch: 5200, train loss: 0.493758

epoch: 3, batch: 5300, train loss: 4.420583

epoch: 3, batch: 5400, train loss: 3.353117

epoch: 3, batch: 5500, train loss: 5.972403

epoch: 3, batch: 5600, train loss: 0.671567

epoch: 3, batch: 5700, train loss: 5.850271

epoch: 3, batch: 5800, train loss: 10.852522

epoch: 3, batch: 5900, train loss: 0.799588

epoch: 3, batch: 6000, train loss: 9.982487

epoch: 3, batch: 6100, train loss: 3.445547

epoch: 3, batch: 6200, train loss: 1.176267

epoch: 3, batch: 6300, train loss: 1.808328

epoch: 3, batch: 6400, train loss: 6.385090

epoch: 3, batch: 6500, train loss: 2.415163

epoch: 3, batch: 6600, train loss: 9.737028

epoch: 3, batch: 6700, train loss: 1.238676

epoch: 3, batch: 6800, train loss: 3.127306

epoch: 3, batch: 6900, train loss: 4.333865

epoch: 3, batch: 7000, train loss: 2.397593

epoch: 3, batch: 7100, train loss: 0.929952

epoch: 3, batch: 7200, train loss: 3.562720

epoch: 3, batch: 7300, train loss: 1.466322

epoch: 3, batch: 7400, train loss: 4.109231

epoch: 3, batch: 7500, train loss: 2.275724

epoch: 3, batch: 7600, train loss: 2.992994

epoch: 3, batch: 7700, train loss: 0.203385

epoch: 3, batch: 7800, train loss: 0.261809


----------Begin test...
--------Time: 7178.537210 sec, epoch: 3, train loss: 3.494339, test loss: 4.192187
save parameters at ./checkpoints/aishell2-C2R71024/epoch_3
epoch: 4, batch: 0, train loss: 5.495980

epoch: 4, batch: 100, train loss: 2.338214

epoch: 4, batch: 200, train loss: 0.396755

epoch: 4, batch: 300, train loss: 2.470742

epoch: 4, batch: 400, train loss: 3.505882

epoch: 4, batch: 500, train loss: 2.412587

epoch: 4, batch: 600, train loss: 3.322598

epoch: 4, batch: 700, train loss: 2.256967

epoch: 4, batch: 800, train loss: 0.577613

epoch: 4, batch: 900, train loss: 2.570874

epoch: 4, batch: 1000, train loss: 0.047726

epoch: 4, batch: 1100, train loss: 0.324474

epoch: 4, batch: 1200, train loss: 0.282062

epoch: 4, batch: 1300, train loss: 0.778969

epoch: 4, batch: 1400, train loss: 6.236031

epoch: 4, batch: 1500, train loss: 1.140688

epoch: 4, batch: 1600, train loss: 0.175609

epoch: 4, batch: 1700, train loss: 0.637570

epoch: 4, batch: 1800, train loss: 0.094978

epoch: 4, batch: 1900, train loss: 2.732108

epoch: 4, batch: 2000, train loss: 1.159999

epoch: 4, batch: 2100, train loss: 0.038865

epoch: 4, batch: 2200, train loss: 7.868989

epoch: 4, batch: 2300, train loss: 0.748584

epoch: 4, batch: 2400, train loss: 0.175382

epoch: 4, batch: 2500, train loss: 0.512726

epoch: 4, batch: 2600, train loss: 1.420633

epoch: 4, batch: 2700, train loss: 6.321202

epoch: 4, batch: 2800, train loss: 3.370454

epoch: 4, batch: 2900, train loss: 4.698178

epoch: 4, batch: 3000, train loss: 2.663106

epoch: 4, batch: 3100, train loss: 2.048889

epoch: 4, batch: 3200, train loss: 4.603179

epoch: 4, batch: 3300, train loss: 1.070913

epoch: 4, batch: 3400, train loss: 1.994867

epoch: 4, batch: 3500, train loss: 0.646172

epoch: 4, batch: 3600, train loss: 0.321078

epoch: 4, batch: 3700, train loss: 1.226859

epoch: 4, batch: 3800, train loss: 1.771087

epoch: 4, batch: 3900, train loss: 0.031228

epoch: 4, batch: 4000, train loss: 4.875581

epoch: 4, batch: 4100, train loss: 1.043890

epoch: 4, batch: 4200, train loss: 18.229454

epoch: 4, batch: 4300, train loss: 0.334113

epoch: 4, batch: 4400, train loss: 1.534934

epoch: 4, batch: 4500, train loss: 1.720564

epoch: 4, batch: 4600, train loss: 1.620892

epoch: 4, batch: 4700, train loss: 1.954703

epoch: 4, batch: 4800, train loss: 2.115548

epoch: 4, batch: 4900, train loss: 2.694378

epoch: 4, batch: 5000, train loss: 3.432078

epoch: 4, batch: 5100, train loss: 1.463280

epoch: 4, batch: 5200, train loss: 0.758176

epoch: 4, batch: 5300, train loss: 4.141545

epoch: 4, batch: 5400, train loss: 0.344258

epoch: 4, batch: 5500, train loss: 2.697536

epoch: 4, batch: 5600, train loss: 1.626532

epoch: 4, batch: 5700, train loss: 1.436877

epoch: 4, batch: 5800, train loss: 3.741819

epoch: 4, batch: 5900, train loss: 0.770224

epoch: 4, batch: 6000, train loss: 6.992294

epoch: 4, batch: 6100, train loss: 1.513828

epoch: 4, batch: 6200, train loss: 1.230060

epoch: 4, batch: 6300, train loss: 0.692867

epoch: 4, batch: 6400, train loss: 2.412071

epoch: 4, batch: 6500, train loss: 2.305099

epoch: 4, batch: 6600, train loss: 2.917746

epoch: 4, batch: 6700, train loss: 1.371458

epoch: 4, batch: 6800, train loss: 2.591405

epoch: 4, batch: 6900, train loss: 1.030827

epoch: 4, batch: 7000, train loss: 1.632725

epoch: 4, batch: 7100, train loss: 1.402560

epoch: 4, batch: 7200, train loss: 5.090604

epoch: 4, batch: 7300, train loss: 3.063606

epoch: 4, batch: 7400, train loss: 1.019077

epoch: 4, batch: 7500, train loss: 0.492291

epoch: 4, batch: 7600, train loss: 2.739882

epoch: 4, batch: 7700, train loss: 0.151203

epoch: 4, batch: 7800, train loss: 3.128645


----------Begin test...
--------Time: 7146.220563 sec, epoch: 4, train loss: 2.263360, test loss: 3.774050
save parameters at ./checkpoints/aishell2-C2R71024/epoch_4
epoch: 5, batch: 0, train loss: 1.822949

epoch: 5, batch: 100, train loss: 2.497970

epoch: 5, batch: 200, train loss: 2.449369

epoch: 5, batch: 300, train loss: 0.063354

epoch: 5, batch: 400, train loss: 3.909078

epoch: 5, batch: 500, train loss: 0.944799

epoch: 5, batch: 600, train loss: 0.182323

epoch: 5, batch: 700, train loss: 1.092998

epoch: 5, batch: 800, train loss: 1.030807

epoch: 5, batch: 900, train loss: 2.507984

epoch: 5, batch: 1000, train loss: 6.386505

epoch: 5, batch: 1100, train loss: 2.466700

epoch: 5, batch: 1200, train loss: 0.516324

epoch: 5, batch: 1300, train loss: 1.501376

epoch: 5, batch: 1400, train loss: 0.832404

epoch: 5, batch: 1500, train loss: 1.327524

epoch: 5, batch: 1600, train loss: 0.080100

epoch: 5, batch: 1700, train loss: 0.137925

epoch: 5, batch: 1800, train loss: 0.646691

epoch: 5, batch: 1900, train loss: 2.008157

epoch: 5, batch: 2000, train loss: 1.323626

epoch: 5, batch: 2100, train loss: 0.958976

epoch: 5, batch: 2200, train loss: 2.360411

epoch: 5, batch: 2300, train loss: 0.569608

epoch: 5, batch: 2400, train loss: 3.128990

epoch: 5, batch: 2500, train loss: 3.142181

epoch: 5, batch: 2600, train loss: 2.684515

epoch: 5, batch: 2700, train loss: 0.367919

epoch: 5, batch: 2800, train loss: 0.149894

epoch: 5, batch: 2900, train loss: 1.105530

epoch: 5, batch: 3000, train loss: 2.839345

epoch: 5, batch: 3100, train loss: 1.299262

epoch: 5, batch: 3200, train loss: 0.593606

epoch: 5, batch: 3300, train loss: 0.465409

epoch: 5, batch: 3400, train loss: 3.860799

epoch: 5, batch: 3500, train loss: 0.029668

epoch: 5, batch: 3600, train loss: 0.221914

epoch: 5, batch: 3700, train loss: 3.828142

epoch: 5, batch: 3800, train loss: 0.935972

epoch: 5, batch: 3900, train loss: 4.375434

epoch: 5, batch: 4000, train loss: 2.698916

epoch: 5, batch: 4100, train loss: 0.646761

epoch: 5, batch: 4200, train loss: 2.938367

epoch: 5, batch: 4300, train loss: 7.195716

epoch: 5, batch: 4400, train loss: 0.074667

epoch: 5, batch: 4500, train loss: 1.954545

epoch: 5, batch: 4600, train loss: 2.213871

epoch: 5, batch: 4700, train loss: 0.020051

epoch: 5, batch: 4800, train loss: 3.116688

epoch: 5, batch: 4900, train loss: 0.713494

epoch: 5, batch: 5000, train loss: 2.005426

epoch: 5, batch: 5100, train loss: 2.744102

epoch: 5, batch: 5200, train loss: 4.650470

epoch: 5, batch: 5300, train loss: 0.755923

epoch: 5, batch: 5400, train loss: 3.617244

epoch: 5, batch: 5500, train loss: 4.400465

epoch: 5, batch: 5600, train loss: 1.101150

epoch: 5, batch: 5700, train loss: 0.406672

epoch: 5, batch: 5800, train loss: 0.392651

epoch: 5, batch: 5900, train loss: 4.438817

epoch: 5, batch: 6000, train loss: 1.141999

epoch: 5, batch: 6100, train loss: 2.569129

epoch: 5, batch: 6200, train loss: 7.277209

epoch: 5, batch: 6300, train loss: 1.192169

epoch: 5, batch: 6400, train loss: 0.297308

epoch: 5, batch: 6500, train loss: 0.315044

epoch: 5, batch: 6600, train loss: 2.594146

epoch: 5, batch: 6700, train loss: 1.225614

epoch: 5, batch: 6800, train loss: 1.691040

epoch: 5, batch: 6900, train loss: 3.710430

epoch: 5, batch: 7000, train loss: 1.067365

epoch: 5, batch: 7100, train loss: 0.657595

epoch: 5, batch: 7200, train loss: 2.106411

epoch: 5, batch: 7300, train loss: 1.317290

epoch: 5, batch: 7400, train loss: 0.621221

epoch: 5, batch: 7500, train loss: 4.148347

epoch: 5, batch: 7600, train loss: 4.061949

epoch: 5, batch: 7700, train loss: 2.529857

epoch: 5, batch: 7800, train loss: 2.521785


----------Begin test...
--------Time: 7159.310300 sec, epoch: 5, train loss: 1.946563, test loss: 3.574854
save parameters at ./checkpoints/aishell2-C2R71024/epoch_5
epoch: 6, batch: 0, train loss: 0.651093

epoch: 6, batch: 100, train loss: 0.243295

epoch: 6, batch: 200, train loss: 2.835956

epoch: 6, batch: 300, train loss: 4.125782

epoch: 6, batch: 400, train loss: 0.991316

epoch: 6, batch: 500, train loss: 0.235862

epoch: 6, batch: 600, train loss: 0.492897

epoch: 6, batch: 700, train loss: 2.444860

epoch: 6, batch: 800, train loss: 1.611092

epoch: 6, batch: 900, train loss: 0.327677

epoch: 6, batch: 1000, train loss: 0.851300

epoch: 6, batch: 1100, train loss: 2.067264

epoch: 6, batch: 1200, train loss: 2.148642

epoch: 6, batch: 1300, train loss: 3.436005

epoch: 6, batch: 1400, train loss: 0.863510

epoch: 6, batch: 1500, train loss: 0.103616

epoch: 6, batch: 1600, train loss: 0.853264

epoch: 6, batch: 1700, train loss: 1.790069

epoch: 6, batch: 1800, train loss: 0.682128

epoch: 6, batch: 1900, train loss: 1.280890

epoch: 6, batch: 2000, train loss: 0.914867

epoch: 6, batch: 2100, train loss: 4.315810

epoch: 6, batch: 2200, train loss: 5.328082

epoch: 6, batch: 2300, train loss: 2.368451

epoch: 6, batch: 2400, train loss: 1.151115

epoch: 6, batch: 2500, train loss: 6.682129

epoch: 6, batch: 2600, train loss: 1.385098

epoch: 6, batch: 2700, train loss: 0.225149

epoch: 6, batch: 2800, train loss: 10.677626

epoch: 6, batch: 2900, train loss: 0.135059

epoch: 6, batch: 3000, train loss: 1.447950

epoch: 6, batch: 3100, train loss: 3.117096

epoch: 6, batch: 3200, train loss: 2.414366

epoch: 6, batch: 3300, train loss: 1.895503

epoch: 6, batch: 3400, train loss: 4.082055

epoch: 6, batch: 3500, train loss: 0.056389

epoch: 6, batch: 3600, train loss: 3.100403

epoch: 6, batch: 3700, train loss: 1.577566

epoch: 6, batch: 3800, train loss: 2.653307

epoch: 6, batch: 3900, train loss: 0.540202

epoch: 6, batch: 4000, train loss: 1.968872

epoch: 6, batch: 4100, train loss: 2.972791

epoch: 6, batch: 4200, train loss: 0.328510

epoch: 6, batch: 4300, train loss: 3.713275

epoch: 6, batch: 4400, train loss: 0.526588

epoch: 6, batch: 4500, train loss: 0.174862

epoch: 6, batch: 4600, train loss: 0.365900

epoch: 6, batch: 4700, train loss: 5.757657

epoch: 6, batch: 4800, train loss: 0.141657

epoch: 6, batch: 4900, train loss: 0.477589

epoch: 6, batch: 5000, train loss: 0.223500

epoch: 6, batch: 5100, train loss: 2.420384

epoch: 6, batch: 5200, train loss: 0.095026

epoch: 6, batch: 5300, train loss: 3.849678

epoch: 6, batch: 5400, train loss: 0.007791

epoch: 6, batch: 5500, train loss: 0.232280

epoch: 6, batch: 5600, train loss: 0.004753

epoch: 6, batch: 5700, train loss: 0.654639

epoch: 6, batch: 5800, train loss: 0.639319

epoch: 6, batch: 5900, train loss: 1.668741

epoch: 6, batch: 6000, train loss: 0.925183

epoch: 6, batch: 6100, train loss: 0.383046

epoch: 6, batch: 6200, train loss: 0.242039

epoch: 6, batch: 6300, train loss: 3.866244

epoch: 6, batch: 6400, train loss: 0.200786

epoch: 6, batch: 6500, train loss: 0.259978

epoch: 6, batch: 6600, train loss: 0.296455

epoch: 6, batch: 6700, train loss: 2.183217

epoch: 6, batch: 6800, train loss: 5.427734

epoch: 6, batch: 6900, train loss: 1.444925

epoch: 6, batch: 7000, train loss: 4.335847

epoch: 6, batch: 7100, train loss: 2.686843

epoch: 6, batch: 7200, train loss: 2.410524

epoch: 6, batch: 7300, train loss: 1.868196

epoch: 6, batch: 7400, train loss: 2.157494

epoch: 6, batch: 7500, train loss: 0.045779

epoch: 6, batch: 7600, train loss: 0.861860

epoch: 6, batch: 7700, train loss: 2.234416

epoch: 6, batch: 7800, train loss: 3.143549


----------Begin test...
--------Time: 7150.315230 sec, epoch: 6, train loss: 1.813958, test loss: 3.560835
save parameters at ./checkpoints/aishell2-C2R71024/epoch_6
epoch: 7, batch: 0, train loss: 0.794593

epoch: 7, batch: 100, train loss: 0.063010

epoch: 7, batch: 200, train loss: 0.259947

epoch: 7, batch: 300, train loss: 0.989992

epoch: 7, batch: 400, train loss: 0.782849

epoch: 7, batch: 500, train loss: 2.329314

epoch: 7, batch: 600, train loss: 3.049159

epoch: 7, batch: 700, train loss: 4.317289

epoch: 7, batch: 800, train loss: 1.773047

epoch: 7, batch: 900, train loss: 1.604572

epoch: 7, batch: 1000, train loss: 0.718874

epoch: 7, batch: 1100, train loss: 2.357306

epoch: 7, batch: 1200, train loss: 1.946692

epoch: 7, batch: 1300, train loss: 7.432366

epoch: 7, batch: 1400, train loss: 0.657803

epoch: 7, batch: 1500, train loss: 0.123836

epoch: 7, batch: 1600, train loss: 0.622665

epoch: 7, batch: 1700, train loss: 0.278305

epoch: 7, batch: 1800, train loss: 0.067902

epoch: 7, batch: 1900, train loss: 0.294450

epoch: 7, batch: 2000, train loss: 1.340011

epoch: 7, batch: 2100, train loss: 0.267885

epoch: 7, batch: 2200, train loss: 1.548278

epoch: 7, batch: 2300, train loss: 0.011446

epoch: 7, batch: 2400, train loss: 1.249145

epoch: 7, batch: 2500, train loss: 0.390392

epoch: 7, batch: 2600, train loss: 0.453957

epoch: 7, batch: 2700, train loss: 1.931110

epoch: 7, batch: 2800, train loss: 4.832843

epoch: 7, batch: 2900, train loss: 1.021723

epoch: 7, batch: 3000, train loss: 0.755540

epoch: 7, batch: 3100, train loss: 0.460897

epoch: 7, batch: 3200, train loss: 0.175431

epoch: 7, batch: 3300, train loss: 0.049077

epoch: 7, batch: 3400, train loss: 0.239238

epoch: 7, batch: 3500, train loss: 0.020800

epoch: 7, batch: 3600, train loss: 0.175616

epoch: 7, batch: 3700, train loss: 2.102186

epoch: 7, batch: 3800, train loss: 2.972794

epoch: 7, batch: 3900, train loss: 4.617167

epoch: 7, batch: 4000, train loss: 5.667333

epoch: 7, batch: 4100, train loss: 0.585390

epoch: 7, batch: 4200, train loss: 0.528181

epoch: 7, batch: 4300, train loss: 0.501382

epoch: 7, batch: 4400, train loss: 0.428987

epoch: 7, batch: 4500, train loss: 1.437518

epoch: 7, batch: 4600, train loss: 0.354210

epoch: 7, batch: 4700, train loss: 1.249467

epoch: 7, batch: 4800, train loss: 1.182256

epoch: 7, batch: 4900, train loss: 2.622112

epoch: 7, batch: 5000, train loss: 1.649060

epoch: 7, batch: 5100, train loss: 3.926280

epoch: 7, batch: 5200, train loss: 0.638586

epoch: 7, batch: 5300, train loss: 0.001876

epoch: 7, batch: 5400, train loss: 4.528771

epoch: 7, batch: 5500, train loss: 0.278101

epoch: 7, batch: 5600, train loss: 0.331425

epoch: 7, batch: 5700, train loss: 0.536026

epoch: 7, batch: 5800, train loss: 1.204297

epoch: 7, batch: 5900, train loss: 0.043462

epoch: 7, batch: 6000, train loss: 0.637679

epoch: 7, batch: 6100, train loss: 1.611418

epoch: 7, batch: 6200, train loss: 0.378212

epoch: 7, batch: 6300, train loss: 0.137194

epoch: 7, batch: 6400, train loss: 5.547968

epoch: 7, batch: 6500, train loss: 0.363798

epoch: 7, batch: 6600, train loss: 0.282947

epoch: 7, batch: 6700, train loss: 2.572091

epoch: 7, batch: 6800, train loss: 0.188284

epoch: 7, batch: 6900, train loss: 0.359621

epoch: 7, batch: 7000, train loss: 0.920308

epoch: 7, batch: 7100, train loss: 2.861112

epoch: 7, batch: 7200, train loss: 2.855144

epoch: 7, batch: 7300, train loss: 2.669215

epoch: 7, batch: 7400, train loss: 1.027123

epoch: 7, batch: 7500, train loss: 1.229098

epoch: 7, batch: 7600, train loss: 0.111369

epoch: 7, batch: 7700, train loss: 0.054574

epoch: 7, batch: 7800, train loss: 1.935571


----------Begin test...
--------Time: 7149.669265 sec, epoch: 7, train loss: 1.373632, test loss: 3.647251
save parameters at ./checkpoints/aishell2-C2R71024/epoch_7
epoch: 8, batch: 0, train loss: 0.338297

epoch: 8, batch: 100, train loss: 0.831887

epoch: 8, batch: 200, train loss: 3.138793

epoch: 8, batch: 300, train loss: 0.012526

epoch: 8, batch: 400, train loss: 0.533528

epoch: 8, batch: 500, train loss: 0.828480

epoch: 8, batch: 600, train loss: 1.926388

epoch: 8, batch: 700, train loss: 0.074344

epoch: 8, batch: 800, train loss: 0.411936

epoch: 8, batch: 900, train loss: 0.095369

epoch: 8, batch: 1000, train loss: 0.277138

epoch: 8, batch: 1100, train loss: 0.323620

epoch: 8, batch: 1200, train loss: 2.112623

epoch: 8, batch: 1300, train loss: 0.168461

epoch: 8, batch: 1400, train loss: 0.019263

epoch: 8, batch: 1500, train loss: 1.465934

epoch: 8, batch: 1600, train loss: 0.122535

epoch: 8, batch: 1700, train loss: 0.120284

epoch: 8, batch: 1800, train loss: 2.681673

epoch: 8, batch: 1900, train loss: 0.404784

epoch: 8, batch: 2000, train loss: 0.621710

epoch: 8, batch: 2100, train loss: 1.252939

epoch: 8, batch: 2200, train loss: 0.076380

epoch: 8, batch: 2300, train loss: 0.928846

epoch: 8, batch: 2400, train loss: 0.310335

epoch: 8, batch: 2500, train loss: 1.542783

epoch: 8, batch: 2600, train loss: 0.181321

epoch: 8, batch: 2700, train loss: 3.789167

epoch: 8, batch: 2800, train loss: 0.210911

epoch: 8, batch: 2900, train loss: 0.422234

epoch: 8, batch: 3000, train loss: 0.756890

epoch: 8, batch: 3100, train loss: 0.133727

epoch: 8, batch: 3200, train loss: 0.545572

epoch: 8, batch: 3300, train loss: 0.323462

epoch: 8, batch: 3400, train loss: 0.859325

epoch: 8, batch: 3500, train loss: 0.024856

epoch: 8, batch: 3600, train loss: 0.837828

epoch: 8, batch: 3700, train loss: 0.130369

epoch: 8, batch: 3800, train loss: 0.911743

epoch: 8, batch: 3900, train loss: 0.507244

epoch: 8, batch: 4000, train loss: 0.357062

epoch: 8, batch: 4100, train loss: 0.018202

epoch: 8, batch: 4200, train loss: 0.067630

epoch: 8, batch: 4300, train loss: 0.762958

epoch: 8, batch: 4400, train loss: 0.412264

epoch: 8, batch: 4500, train loss: 0.533710

epoch: 8, batch: 4600, train loss: 0.731990

epoch: 8, batch: 4700, train loss: 0.144905

epoch: 8, batch: 4800, train loss: 0.316012

epoch: 8, batch: 4900, train loss: 0.462354

epoch: 8, batch: 5000, train loss: 4.554255

epoch: 8, batch: 5100, train loss: 0.815320

epoch: 8, batch: 5200, train loss: 0.005195

epoch: 8, batch: 5300, train loss: 0.919217

epoch: 8, batch: 5400, train loss: 1.062766

epoch: 8, batch: 5500, train loss: 1.132786

epoch: 8, batch: 5600, train loss: 0.153453

epoch: 8, batch: 5700, train loss: 0.633434

epoch: 8, batch: 5800, train loss: 5.385805

epoch: 8, batch: 5900, train loss: 1.566629

epoch: 8, batch: 6000, train loss: 5.184363

epoch: 8, batch: 6100, train loss: 0.147141

epoch: 8, batch: 6200, train loss: 0.397521

epoch: 8, batch: 6300, train loss: 1.056859

epoch: 8, batch: 6400, train loss: 0.068940

epoch: 8, batch: 6500, train loss: 0.695524

epoch: 8, batch: 6600, train loss: 2.507099

epoch: 8, batch: 6700, train loss: 0.526917

epoch: 8, batch: 6800, train loss: 0.539074

epoch: 8, batch: 6900, train loss: 1.596161

epoch: 8, batch: 7000, train loss: 0.614055

epoch: 8, batch: 7100, train loss: 0.627194

epoch: 8, batch: 7200, train loss: 0.728887

epoch: 8, batch: 7300, train loss: 0.257877

epoch: 8, batch: 7400, train loss: 3.234451

epoch: 8, batch: 7500, train loss: 0.474181

epoch: 8, batch: 7600, train loss: 0.133275

epoch: 8, batch: 7700, train loss: 0.284832

epoch: 8, batch: 7800, train loss: 0.921081


----------Begin test...
--------Time: 7134.385142 sec, epoch: 8, train loss: 0.889707, test loss: 3.641790
save parameters at ./checkpoints/aishell2-C2R71024/epoch_8
epoch: 9, batch: 0, train loss: 0.087644

epoch: 9, batch: 100, train loss: 0.158442

epoch: 9, batch: 200, train loss: 0.423399

epoch: 9, batch: 300, train loss: 0.571801

epoch: 9, batch: 400, train loss: 0.528581

epoch: 9, batch: 500, train loss: 0.347959

epoch: 9, batch: 600, train loss: 0.013101

epoch: 9, batch: 700, train loss: 0.074344

epoch: 9, batch: 800, train loss: 0.440787

epoch: 9, batch: 900, train loss: 7.387760

epoch: 9, batch: 1000, train loss: 0.007569

epoch: 9, batch: 1100, train loss: 0.377315

epoch: 9, batch: 1200, train loss: 0.097703

epoch: 9, batch: 1300, train loss: 0.843618

epoch: 9, batch: 1400, train loss: 0.714690

epoch: 9, batch: 1500, train loss: 0.045370

epoch: 9, batch: 1600, train loss: 0.615674

epoch: 9, batch: 1700, train loss: 1.284528

epoch: 9, batch: 1800, train loss: 0.931872

epoch: 9, batch: 1900, train loss: 1.229634

epoch: 9, batch: 2000, train loss: 0.104937

epoch: 9, batch: 2100, train loss: 0.903776

epoch: 9, batch: 2200, train loss: 0.450301

epoch: 9, batch: 2300, train loss: 1.095898

epoch: 9, batch: 2400, train loss: 0.406137

epoch: 9, batch: 2500, train loss: 0.535328

epoch: 9, batch: 2600, train loss: 0.053230

epoch: 9, batch: 2700, train loss: 0.074350

epoch: 9, batch: 2800, train loss: 0.025529

epoch: 9, batch: 2900, train loss: 0.146427

epoch: 9, batch: 3000, train loss: 0.285183

epoch: 9, batch: 3100, train loss: 0.809488

epoch: 9, batch: 3200, train loss: 0.501330

epoch: 9, batch: 3300, train loss: 0.538269

epoch: 9, batch: 3400, train loss: 0.287293

epoch: 9, batch: 3500, train loss: 0.462454

epoch: 9, batch: 3600, train loss: 0.214479

epoch: 9, batch: 3700, train loss: 2.367237

epoch: 9, batch: 3800, train loss: 0.203673

epoch: 9, batch: 3900, train loss: 0.255405

epoch: 9, batch: 4000, train loss: 0.706800

epoch: 9, batch: 4100, train loss: 1.620525

epoch: 9, batch: 4200, train loss: 2.547310

epoch: 9, batch: 4300, train loss: 0.113660

epoch: 9, batch: 4400, train loss: 0.021541

epoch: 9, batch: 4500, train loss: 2.309001

epoch: 9, batch: 4600, train loss: 0.004737

epoch: 9, batch: 4700, train loss: 0.248628

epoch: 9, batch: 4800, train loss: 0.005716

epoch: 9, batch: 4900, train loss: 1.549666

epoch: 9, batch: 5000, train loss: 0.694051

epoch: 9, batch: 5100, train loss: 0.481169

epoch: 9, batch: 5200, train loss: 0.431821

epoch: 9, batch: 5300, train loss: 1.746249

epoch: 9, batch: 5400, train loss: 0.893078

epoch: 9, batch: 5500, train loss: 0.006203

epoch: 9, batch: 5600, train loss: 0.071961

epoch: 9, batch: 5700, train loss: 0.091285

epoch: 9, batch: 5800, train loss: 0.587866

epoch: 9, batch: 5900, train loss: 2.018165

epoch: 9, batch: 6000, train loss: 0.081317

epoch: 9, batch: 6100, train loss: 0.722717

epoch: 9, batch: 6200, train loss: 0.738533

epoch: 9, batch: 6300, train loss: 1.005296

epoch: 9, batch: 6400, train loss: 2.148400

epoch: 9, batch: 6500, train loss: 1.853372

epoch: 9, batch: 6600, train loss: 1.284894

epoch: 9, batch: 6700, train loss: 0.008523

epoch: 9, batch: 6800, train loss: 1.624385

epoch: 9, batch: 6900, train loss: 0.011661

epoch: 9, batch: 7000, train loss: 2.432719

epoch: 9, batch: 7100, train loss: 0.258927

epoch: 9, batch: 7200, train loss: 1.563539

epoch: 9, batch: 7300, train loss: 0.015231

epoch: 9, batch: 7400, train loss: 1.824703

epoch: 9, batch: 7500, train loss: 0.115066

epoch: 9, batch: 7600, train loss: 0.300430

epoch: 9, batch: 7700, train loss: 0.620520

epoch: 9, batch: 7800, train loss: 1.808357


----------Begin test...
--------Time: 7190.891959 sec, epoch: 9, train loss: 0.765450, test loss: 3.624283
save parameters at ./checkpoints/aishell2-C2R71024/epoch_9
save parameters at ./checkpoints/aishell2-C2R71024/step_final

------------Training finished!!!-------------
[1;33mλ [1;37mdgx-18-04 [1;32m/DeepSpeech/examples/aishell2[1;33m[0m packet_write_wait: Connection to 10.110.49.17 port 22: Broken pipe
(base) [36mkakao[m@[32mkakao-mlt:[33;1m~[m$ 